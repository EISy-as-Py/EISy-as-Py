{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook to build up basic CNN model and use the cat and dog image provided by the Microsoft to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetImages/Cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 12501/12501 [00:13<00:00, 935.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetImages/Dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 12501/12501 [00:14<00:00, 870.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats: 12476\n",
      "Dogs: 12470\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "REBUILD_DATA = True\n",
    "\n",
    "## pre-processing step\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"PetImages/Cat\" # give the directory of images\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}  \n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0 # make sure the \"balance\"\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS: #iterate the directory\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):  # iterate all the image within the directory, f -> the file name\n",
    "                try:\n",
    "                    path = os.path.join(label, f) # get the full path to the image\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # convert the iimage to gray scale (optional)\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "\n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"Cats:\", self.catcount)\n",
    "        print(\"Dogs:\", self.dogcount)\n",
    "        \n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[180, 186, 187, ...,  38,  56,  86],\n",
      "       [171, 168, 162, ..., 111,  75,  77],\n",
      "       [127, 150, 164, ...,  67,  57,  77],\n",
      "       ...,\n",
      "       [ 47,  53,  54, ...,  96,  83,  65],\n",
      "       [ 35,  43,  53, ...,  80,  90, 101],\n",
      "       [ 37,  37,  41, ...,  75,  61, 111]], dtype=uint8)\n",
      " array([0., 1.])]\n",
      "[array([[  4,   6,   9, ...,   0,   0,   0],\n",
      "       [  5,   8,   8, ...,   4,   0,   0],\n",
      "       [  5,   9,  10, ...,   2,   0,   0],\n",
      "       ...,\n",
      "       [ 34,  62,  69, ...,  52,  44, 142],\n",
      "       [ 50,  60,  66, ...,  78,  70, 136],\n",
      "       [  7,  55,  60, ...,  77,  73, 108]], dtype=uint8)\n",
      " array([1., 0.])]\n",
      "[array([[ 35,  35,  34, ...,  41,  42,  41],\n",
      "       [ 35,  34,  35, ...,  41,  40,  40],\n",
      "       [ 34,  36,  34, ...,  40,  40,  41],\n",
      "       ...,\n",
      "       [245, 243, 239, ..., 250, 247, 248],\n",
      "       [247, 248, 244, ..., 248, 250, 248],\n",
      "       [245, 248, 249, ..., 255, 255, 255]], dtype=uint8)\n",
      " array([1., 0.])]\n",
      "[array([[191, 138, 152, ..., 205, 173, 155],\n",
      "       [212, 192, 123, ..., 166, 189, 191],\n",
      "       [150, 138, 172, ..., 188, 129, 140],\n",
      "       ...,\n",
      "       [190, 200, 163, ..., 212, 227, 117],\n",
      "       [145, 134, 123, ..., 164, 148, 187],\n",
      "       [176, 204,  89, ..., 203, 169, 137]], dtype=uint8)\n",
      " array([0., 1.])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(training_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_data[1][0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  4,   6,   9, ...,   0,   0,   0],\n",
      "       [  5,   8,   8, ...,   4,   0,   0],\n",
      "       [  5,   9,  10, ...,   2,   0,   0],\n",
      "       ...,\n",
      "       [ 34,  62,  69, ...,  52,  44, 142],\n",
      "       [ 50,  60,  66, ...,  78,  70, 136],\n",
      "       [  7,  55,  60, ...,  77,  73, 108]], dtype=uint8)\n",
      " array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(training_data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,   6,   9, ...,   0,   0,   0],\n",
       "       [  5,   8,   8, ...,   4,   0,   0],\n",
       "       [  5,   9,  10, ...,   2,   0,   0],\n",
       "       ...,\n",
       "       [ 34,  62,  69, ...,  52,  44, 142],\n",
       "       [ 50,  60,  66, ...,  78,  70, 136],\n",
       "       [  7,  55,  60, ...,  77,  73, 108]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Making layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # 1st layer\n",
    "        # 5 -> kernel size, which means that it will form a 5 by 5 window \n",
    "        # to roll over the data to find features\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "        x = torch.randn(50, 50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        # Eventually output to at least one linear layer\n",
    "        # self.fc1 = nn.Linear(???, 512)\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)        \n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "        \n",
    "        #print(x[0].shape)\n",
    "        \n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear) # flatten\n",
    "        x = F.relu(self.fc1(x)) # put into the first fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "net = Net()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
    "X = X/255.0  # scaling the imagery which means that turn the pixel values form (0~255) to (0~1)\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "\n",
    "# Separate the training ant testing data\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452\n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:40<00:00,  2.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:46<00:00,  2.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:32<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1412, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # tqdm -> show the progress bar\n",
    "        #print(i, i+BATCH_SIZE)\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        \n",
    "        net.zero_grad()\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2494/2494 [00:09<00:00, 256.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.721\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "            \n",
    "        total += 1\n",
    "        \n",
    "print(\"Accuracy:\", round(correct/total,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_pass(X, y, train=False):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    loss = loss_function(outputs, y)\n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return acc, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875 tensor(0.2046)\n"
     ]
    }
   ],
   "source": [
    "def test(size=32):    \n",
    "    randsom_start = np.random.randint(len(test_X)-size)\n",
    "    #X, y = text_X[:size], test_y[:size]\n",
    "    X, y =test_X[randsom_start:randsom_start+size], test_y[randsom_start:randsom_start+size] \n",
    "    # slice start from random point\n",
    "    with torch.no_grad():\n",
    "        val_acc, val_loss = fwd_pass(X.view(-1, 1, 50, 50), y)\n",
    "    return val_acc, val_loss\n",
    "\n",
    "val_acc, val_loss = test(size=32)\n",
    "print(val_acc, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-1583585312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:49<00:00,  2.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:55<00:00,  1.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:46<00:00,  2.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [01:48<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "print(MODEL_NAME)\n",
    "\n",
    "def train():\n",
    "    BATCH_SIZE = 100\n",
    "    EPOCHS = 4\n",
    "    with open(\"model.log\", \"a\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "                batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "                batch_y = train_y[i:i+BATCH_SIZE]\n",
    "                \n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
    "                if i % 50 == 0: \n",
    "                    val_acc, val_loss = test(size=32)\n",
    "                    f.write(f\"{MODEL_NAME}, {round(time.time(),3)}, {round(float(acc),2)}, {round(float(loss),4)}, {round(float(val_acc),2)}, {round(float(val_loss),4)}\\n\")\n",
    "                    \n",
    "train()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
