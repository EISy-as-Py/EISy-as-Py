{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Guidance on Image Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5d7cc609da56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#Following are all included in environment.yml \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing of Data\n",
    "The following will allow the users to import the image file (.png) to turn it into numpy array for processing.\n",
    "This class/function will be used once Build_Data function is called.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EISDataImport():\n",
    "    \"\"\"Data Import and Pre-Processing\"\"\"\n",
    "\n",
    "    def DataImporter_Training(self, k, path_List_training,\n",
    "                              image_width, image_height):\n",
    "        \"\"\"\n",
    "        Import the training image file (.png) into the model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        k: The total number of the type.\n",
    "           (Setting the maximum value equal 7 by defult)\n",
    "        path_list_training: A list containing the path of training folder.\n",
    "                            One index for one path only.\n",
    "                            Last index is the nparray file name (XXX.npy).\n",
    "        image_width: The target width after resize\n",
    "        image_height: The target height after resize\n",
    "        \"\"\"\n",
    "        path_list = path_List_training\n",
    "        countImage_Training = [0, 0, 0, 0, 0, 0, 0]\n",
    "        training_data = []\n",
    "        # Iterate the directory\n",
    "        print(len(path_list))\n",
    "        for label in range(len(path_list)):\n",
    "            print(path_list[label])\n",
    "            # Iterate all the image within the directory, f -> the file name\n",
    "            for f in tqdm(os.listdir(path_list[label])):\n",
    "                # Get the full path to the image\n",
    "                path = os.path.join(path_list[label], f)\n",
    "                if \"png\" in path:\n",
    "                    # Read images in the given path and turn into nparray.\n",
    "                    # Convert the iimage to gray scale (optional)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, (image_width, image_height))\n",
    "                    # Label the image with np.eye() matrix.\n",
    "                    training_data.append([path, np.array(img),\n",
    "                                          np.eye(k-1)[label]])\n",
    "                    for i in range(k):\n",
    "                        if label == i:\n",
    "                            countImage_Training[i] += 1\n",
    "\n",
    "        np.random.shuffle(training_data)\n",
    "        np.save(path_list[-1], training_data)\n",
    "        for i in range(len(path_list)-1):\n",
    "            print(path_List_training[i], \":\", countImage_Training[i])\n",
    "        return training_data\n",
    "\n",
    "    def DataImporter_Predict(self, k, path_List_predict,\n",
    "                             image_width, image_height):\n",
    "        \"\"\"\n",
    "        Import the testing image file (.png) into the model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        k: The total number of path(folder) \n",
    "           (Setting the maximum value equal 10 by defult)\n",
    "        path_list_training: A list containing the path of training folder.\n",
    "                            One index for one path only.\n",
    "                            Last index is the nparray file name (XXX.npy).\n",
    "        image_width: The target width after resize\n",
    "        image_height: The target height after resize\n",
    "        \"\"\"\n",
    "        path_list = path_List_predict\n",
    "        countImage_Predict = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        #training_data = []\n",
    "        # Iterate the directory\n",
    "        for label in range(len(path_list)):\n",
    "            # Iterate all the image within the directory, f -> the file name\n",
    "            for f in tqdm(os.listdir(path_list[label])):\n",
    "                # Get the full path to the image\n",
    "                path = os.path.join(path_list[label], f)\n",
    "                if \"png\" in path:\n",
    "                    # Read images in the given path and turn into nparray.\n",
    "                    # Convert the iimage to gray scale (optional)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, (image_width, image_height))\n",
    "                    training_data.append([path, np.array(img)])\n",
    "                    # Count the number of image\n",
    "                    for i in range(k):\n",
    "                        if label == i:\n",
    "                            countImage_Predict[i] += 1\n",
    "\n",
    "        np.random.shuffle(training_data)\n",
    "        np.save(path_list[-1], training_data)\n",
    "        for i in range(len(path_list)):\n",
    "            print(path_List_predict[i], \":\", countImage_Predict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Data(Training, k, path_list, image_width, image_height):\n",
    "    '''This will allow us to use EISData() to preprocess train/test data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    Training = True (Class.DataImporter_Training) will be used/ False (vice versa)\n",
    "    k = the total number of path\n",
    "    path_list = [string of folder path on local drive]\n",
    "    image_width/height for rescaling\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    training data [path,numpy array for images, label(if Training=True)]\n",
    "    '''\n",
    "    Class = EISData()\n",
    "    if Training is True:\n",
    "        Class.DataImporter_Training(k, path_list, image_width, image_height)\n",
    "    else :\n",
    "        Class.DataImporter_Predict(k, path_list, image_width, image_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afte running Build_Data, .npy file is created in the same directory where the image data is imported. If the purpose of using images is for training, (Training=True), then  the .npy file is saved as the name of the last file name in the input array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Make sure to check the name of .npy file created in the directory.\n",
    "Then, load the properly processed data, .npy, for further data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(np_ndarray_file):\n",
    "    \"\"\"\n",
    "    Load the data from the .npy file to check if all the images\n",
    "    have been in the program.\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    np_ndarray_file: The XXX.npy file name.\n",
    "                     Should be identical to the last index in path list\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    training_data:  the dataset expressed in numpy array form.\n",
    "                    type -> numpy.ndarray\n",
    "\n",
    "    \"\"\"\n",
    "    training_data = np.load(np_ndarray_file, allow_pickle=True)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=(load_training_data('SingleHump.npy'))\n",
    "print(training_data)\n",
    "print(len('SingleHump.npy'))\n",
    "training_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comfirming Data\n",
    "Use the functions data_information, and plotting_data in order to make sure that the image data has been imported correctly. From the data_information, this will ensure the user to know what width and height of the file used for convoluted neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_information(training_data):\n",
    "    \"\"\"\n",
    "    Check the size of image and dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    training_data: the data loading from \"eis_training_data.npy\"\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Type of training_data:\", type(training_data))\n",
    "    print(\"Size of training_data:\", len(training_data))\n",
    "    print(\"Size of image(after rescale):\", training_data[0][1].shape[1],\n",
    "          \"x\", training_data[0][1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_information(training_data)\n",
    "print(training_data.shape)\n",
    "print(training_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_data(training_data, k):\n",
    "    \"\"\"\n",
    "    Show the assigned image with matplotlib package.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    training_data: the data loading from \"eis_training_data.npy\"\n",
    "    k:  assign one image in training_data to show.\n",
    "        k should fall in the range of dataset size.\n",
    "        Rang: 0-size of training data\n",
    "\n",
    "    \"\"\"\n",
    "    print(training_data[k][0])\n",
    "    plt.imshow(training_data[k][1])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data(training_data, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convoluted Neural Network\n",
    "The following class, Net(nn.Module) will proceed the neural network training using the training data set. Use the function, type_prediction, to proceed with training. \n",
    "\n",
    "Depending on input size, the following equation has been used to calculate the size of image in every process:\n",
    "\n",
    "$$n_{out} = [\\frac{n_{in}+2p-k}{s}]+1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network Model\"\"\"\n",
    "    def __init__(self, input_size, image_width, image_height,\n",
    "                 firstHidden, kernel_size, output_size):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size: 1\n",
    "        image_width: The width of input images.\n",
    "                     this is provided from the data_information function\n",
    "        image_height: The width of input images.\n",
    "                     this is provided from the data_information function\n",
    "        firstHidden: The size of first hidden layer.\n",
    "                     The size of next layer will be twice of the current layer\n",
    "                     Ex: 1st is 8, 2nd will be 16, 3rd will be 24 and so on.\n",
    "                     Number of hidden layer is set as 4 by default.\n",
    "        kernel_size: It will form a subwindom with size of kernel to scan over\n",
    "                     the original image.\n",
    "                     kernel_size must be an odd integer,\n",
    "                     usually not larger than 7\n",
    "        output_size: The number of final target category.\n",
    "\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size, firstHidden, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(firstHidden, firstHidden*2, kernel_size)\n",
    "        self.conv3 = nn.Conv2d(firstHidden*2, firstHidden*4, kernel_size)\n",
    "        self.conv4 = nn.Conv2d(firstHidden*4, firstHidden*8, kernel_size)\n",
    "        # Get size\n",
    "        x = torch.randn(image_height, image_width).view(-1, 1, image_height,\n",
    "                                                        image_width)\n",
    "        conv_to_linear = self.last_conv_neuron(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_to_linear, 64)\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "\n",
    "    def last_conv_neuron(self, x):\n",
    "        \"\"\"\n",
    "        Calculate how many neurons that the last convolutional layer will\n",
    "        connect to the linear hidden layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: a random torch tensor with size (-1, 1, image_height, image_width)\n",
    "        Ex: x = torch.randn(image_height, image_width\n",
    "                            ).view(-1, 1, image_height, image_width)\n",
    "        \"\"\"\n",
    "        x = self.convs(x)\n",
    "        conv_to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return conv_to_linear\n",
    "\n",
    "    def convs(self, x):\n",
    "        \"\"\"\n",
    "        Put the image into the convolutional hidden layer. Scan over the\n",
    "        original image to and use the max pooling function (with size 2) to\n",
    "        determine the one number to represent the sub-image.\n",
    "\n",
    "        \"\"\"\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), (2, 2))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.convs(x)\n",
    "        conv_to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        # Flatten the data\n",
    "        xF = x.view(-1, conv_to_linear)\n",
    "        # put into the first fully connected layer\n",
    "        output = torch.sigmoid(self.fc1(xF))\n",
    "        output = self.fc2(output)\n",
    "        return F.softmax(output, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the data set, separate Train and Test to confirm the training is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_separation(data, ratio_of_testing, TRAIN):\n",
    "    \"\"\"Separate the training and testing data.\n",
    "    Parameters\n",
    "    -------------\n",
    "    data: A tensor. Tranformed image numpy array.\n",
    "    ratio_of_testing. Float. 0.2 = 20% of data is stored as testing data\n",
    "    Train: True/False\n",
    "    \"\"\"\n",
    "    VAL_PCT = ratio_of_testing\n",
    "    val_size = int(len(data)*VAL_PCT)\n",
    "\n",
    "    if TRAIN is True:\n",
    "        train_data = data[:-val_size]\n",
    "        print(\"Training Samples:\", len(train_data))\n",
    "        return train_data\n",
    "    test_data = data[-val_size:]\n",
    "    print(\"Testing Samples:\", len(test_data))\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_of_testing=0.2\n",
    "train_data=data_separation(training_data, ratio_of_testing, True)\n",
    "test_data=data_separation(training_data, ratio_of_testing, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the function, learning, firstly, transform the array image data to tensor. Image_to_tensor function will turn the numpy array of ###.npy (training data) into a tensor and type_to_tensor function will allow matrix created in preprocessing to identify each image input in the format of identity matrix to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(training_data, image_height, image_width):\n",
    "    \"\"\"Transform the array image into tensor.\"\"\"\n",
    "    X = torch.Tensor([i[1] for i in training_data]\n",
    "                     ).view(-1, image_height, image_width)\n",
    "    return X/255. #normalize X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=image_to_tensor(train_data, 536, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = image_to_tensor(test_data, 536, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_to_tensor(training_data):\n",
    "    \"\"\"Transform the array type into tensor.\"\"\"\n",
    "    y = torch.Tensor([i[2] for i in training_data])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=type_to_tensor(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = type_to_tensor(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and Accuracy\n",
    "Afer the test and train functions are defined and all the arrays and transformed to tensors, proceed with the functions, learning and accuracy, to determine how well the model performs. The loss function is a continuous function which determines how easy each categories are classified. Lower the value, less of the confusion the model had for the classification. Accuracy is a discrete function which will show whether or not the function made a correct prediction or not. Again, since both of them determines the model performance, for a better performance, large database is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(train_data1, train_data2, input_size, image_width, image_height,\n",
    "             firstHidden, kernel_size, output_size, learning_rate, BATCH_SIZE,\n",
    "             EPOCHS):\n",
    "    \"\"\"\n",
    "    parameter\n",
    "    ---------\n",
    "    train_data1 = X_train [image data]\n",
    "    train_data2 = y_train [type data]\n",
    "    input_size = 1\n",
    "    image_width, image_height = same as the ones defined for preprocessing\n",
    "    firstHidden = 8, typically\n",
    "    kernel_size = 4\n",
    "    output_size = 2 [0=bad, 1=pass]\n",
    "    learning_rate = 0.001 at default for pytorch\n",
    "    BATCH_SIZE = 10 the number of images used for training at a time\n",
    "    EPOCHS = 1\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(Net(input_size, image_width, image_height,\n",
    "                               firstHidden, kernel_size, output_size\n",
    "                               ).parameters(), lr=learning_rate) \n",
    "    loss_function = nn.L1Loss() #L1Loss() used for our model (complicated cnn model)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_data1), BATCH_SIZE)):\n",
    "            batch_data1 = train_data1[i:i+BATCH_SIZE].view(-1, 1,\n",
    "                                                           image_height,\n",
    "                                                           image_width)\n",
    "            batch_data2 = train_data2[i:i+BATCH_SIZE]\n",
    "\n",
    "            Net(input_size, image_width, image_height, firstHidden,\n",
    "                kernel_size, output_size).zero_grad()\n",
    "            outputs = Net(input_size, image_width, image_height, firstHidden,\n",
    "                          kernel_size, output_size)(batch_data1)\n",
    "            loss = loss_function(outputs, batch_data2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = learning(X, y, 1, 800, 536, 8, 4, 2, 0.001, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_data1, test_data2, input_size, image_width, image_height,\n",
    "             firstHidden, kernel_size, output_size):\n",
    "    \"\"\"\n",
    "    This function tells how well the predictions are made based on the correctness. \n",
    "    Parameters:\n",
    "    --------------\n",
    "    test_data1 = tensor. From image_to_tensor\n",
    "    test_data2 = tensor. From type_to_tensor\n",
    "    input_size,image_width,image_height,firstHidden,kernel_size,output_size same as the function call for learning\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_data1))):\n",
    "            real_type = torch.argmax(test_data2[i])\n",
    "            net_out_train = Net(input_size, image_width, image_height,\n",
    "                                firstHidden, kernel_size, output_size\n",
    "                                )(test_data1[i].view(-1, 1, image_height,\n",
    "                                                     image_width))[0]\n",
    "            predicted_type = torch.argmax(net_out_train)\n",
    "\n",
    "            if predicted_type == real_type:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    print(\"Accuracy:\", round(correct/total, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy(X_test, y_test, 1, 800, 536,8, 4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data Processing Model\n",
    "This function sorts the raw data into two categories, bad or passing. If detailed_information=True, this function will show the name of raw data that are defined bad. However, if a raw data passes the test, this function will collect the passing images in numpy arrays and save it in the local directory as \"processed.npy\". This numpy array could be furthered used in CNN_model.py to classify it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_prediction(k, path_List_training, tensor_data, array_data,\n",
    "                    input_size, image_width, image_height, firstHidden,\n",
    "                    kernel_size, output_size, detailed_information):\n",
    "    \"\"\"\n",
    "    Predict which type the input image is and print out the total number of\n",
    "    each type.\n",
    "    (Optional) Print out the predicted type and file name for each image.\n",
    "    Parameters\n",
    "    ----------\n",
    "    k\n",
    "    path_List_training : Same as the parameters of nn model\n",
    "    tensor_data: from the return of image_to_tensor() function.\n",
    "    array_data: from the return of load_array_data() function.\n",
    "    input_size : 1\n",
    "    image_width: The target width after resize\n",
    "    image_height: The target height after resize\n",
    "    firstHidden: The size of first hidden layer.\n",
    "    kernel_size: It will form a subwindom with size of kernel to scan over\n",
    "                 the original image.\n",
    "    output_size: The number of final target type.\n",
    "    detailed information: Show the predicted type and file\n",
    "                          name for each image or not\n",
    "    \"\"\"\n",
    "    passing_data=[]\n",
    "    countImage_predicted_type = [0, 0, 0, 0, 0, 0, 0]\n",
    "    for i in range(len(Input_data)):\n",
    "        net_out_predict = Net(input_size, image_width, image_height,\n",
    "                              firstHidden, kernel_size, output_size)(Input_data[i].view(-1, 1, image_height,image_width))[0]\n",
    "        predicted_type = torch.argmax(net_out_predict)\n",
    "        for Type in range(k):\n",
    "            if predicted_type == 0:\n",
    "                countImage_predicted_type[Type] += 1\n",
    "                # Print out the detailed information.\n",
    "                if detailed_information is True:\n",
    "                    #The following messages are optional. Mute for faster processing time.\n",
    "                    print(\"Warning! Type Prediction:\", path_List_training[Type])\n",
    "                    print(\"Path and File Name\", array_data[i][0])\n",
    "            else:\n",
    "                countImage_predicted_type[Type] += 1\n",
    "                passing_data.append([array_data[i][0], array_data[i][1]])\n",
    "                \n",
    "    for i in range(len(path_List_training)-1):\n",
    "        print(path_List_training[i], \":\", countImage_predicted_type[i])\n",
    "    \n",
    "    np.save('processed.npy', passing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NS = \"/Users/mkim91/Desktop/Direct/Eisy_as_py/eisy/cnn/Neural_Network/Noisy\" # Determine the number of type and then give the directory of each type of image\n",
    "SH = \"/Users/mkim91/Desktop/Direct/Eisy_as_py/eisy/cnn/Neural_Network/SingleHump\"\n",
    "path_List_training= [NS, SH]\n",
    "k=len(path_List_training)-1\n",
    "Input_data=X\n",
    "np_array_data=training_data\n",
    "input_size=1\n",
    "image_width=800\n",
    "image_height=536\n",
    "firstHidden=8\n",
    "kernel_size=4\n",
    "output_size=2\n",
    "detailed= False\n",
    "type_prediction(k, path_List_training, Input_data, np_array_data,\n",
    "                    input_size, image_width, image_height, firstHidden,\n",
    "                    kernel_size, output_size,detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
